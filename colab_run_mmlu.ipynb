{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PackLLM – MMLU Fusion Experiment (Google Colab)\n",
    "Runs the *opt-fusion* experiment on the MMLU benchmark using \n",
    "`NousResearch/Llama-2-7b-hf` and three additional 7-B models.\n",
    "Results are stored in `outputs/` and key metrics printed at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# ↳ Install libraries (quiet mode)\n",
    "!pip -q install transformers==4.41.1 accelerate datasets evaluate scikit-learn sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "# ↳ Clone the PackLLM repo (public, no auth needed)\n",
    "!git clone -q https://github.com/tenet-diver/ppack_of_llamas.git\n",
    "%cd ppack_of_llamas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-internal-reqs"
   },
   "outputs": [],
   "source": [
    "# ↳ Install any repo-specific requirements\n",
    "!pip -q install -r downstream_tasks/requirements.txt || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-experiment"
   },
   "outputs": [],
   "source": [
    "# ↳ Run the fusion experiment for the MMLU benchmark\n",
    "import os, json, pathlib, subprocess, textwrap\n",
    "MODEL_NAMES = ','.join([\n",
    "    'NousResearch/Llama-2-7b-hf',\n",
    "    'mistralai/Mistral-7B-v0.1',\n",
    "    'microsoft/phi-2',\n",
    "    'Deci/DeciLM-7B'\n",
    "])\n",
    "cmd = textwrap.dedent(f'''\\\n    python downstream_tasks/main.py \\n      --task_name mmlu \\n      --fusion opt \\n      --model_name \"{MODEL_NAMES}\" \\n      --few_shot 0 \\n      --data_cache_dir datasets \\n      --output_dir outputs/fusion_opt_mmlu \\n      --annotation_size 5 \\n      --seed 1\\\n    ''')\n",
    "print('Executing:\n', cmd)\n",
    "subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "display-results"
   },
   "outputs": [],
   "source": [
    "# ↳ Display the summary results if the script produced a metrics file\n",
    "import glob, pandas as pd, json, os, pprint, pathlib\n",
    "results_files = glob.glob('outputs/fusion_opt_mmlu/**/*.json', recursive=True)\n",
    "if results_files:\n",
    "    df_list = []\n",
    "    for f in results_files:\n",
    "        with open(f) as fh:\n",
    "            data = json.load(fh)\n",
    "        df_list.append({'file': pathlib.Path(f).name, **data})\n",
    "    display(pd.DataFrame(df_list))\n",
    "else:\n",
    "    print('No JSON results found yet. Check logs above.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PackLLM_MMLU_Fusion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
